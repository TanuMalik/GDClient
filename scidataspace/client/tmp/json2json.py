import json
import Queue
file_in = "filex1.json"
file_out_entities = "filex1_entities.json"
file_out_activities = "filex1_activities.json"

def filter_entity(entity):
    entity_name = entity.split('--')[1]
    if entity_name.startswith("/home/ubuntu/default/"):
        return True
    if entity_name.startswith("/home/ubuntu/.cache/matplotlib"):
        return True
    if entity_name.startswith("/home/ubuntu/.config/matplotlib"):
        return True
    if entity_name.endswith(".pyc"):
        return True

    # print " --- ", entity_name," is not filtered"
    return False

def create_entities_json(json_dict):
    #print json.dumps(json_dict, indent=4, sort_keys=True)

    activities     = json_dict.get('activity',{})
    entities       = json_dict.get('entity',{})
    used           = json_dict.get('used',{})
    used_entities  = [used[key]['prov:entity'] for key in used]
    used_activities= [used[key]['prov:activity'] for key in used]
    wasgeneratedby = json_dict.get('wasgeneratedby',{})
    wasgeneratedby_entities  = [wasgeneratedby[key]['prov:entity'] for key in wasgeneratedby]
    wasgeneratedby_activities= [wasgeneratedby[key]['prov:activity'] for key in wasgeneratedby]

    entities_queue = Queue.Queue()
    processed_entities = []

    files_selected = []
    for entity in entities:
        if (entity not in wasgeneratedby_entities):
            # this is a basic entity ; we add as it is
            # files_dict[entity]=entities[entity]
            if not filter_entity(entity):
                entities_queue.put(entity)
                files_selected.append(entity)
            processed_entities.append(entity)

    # let's verify that basic files are ok
    # for file in files_dict:
    #     if file not in used_entities:
    #         print "ERROR: strange file ", file

    # using format according to example 25 from http://www.w3.org/Submission/2013/SUBM-prov-json-20130424/
    # "prov:generatedEntity" and "prov:usedEntity"

    namespace = "_"
    wdf_count = 0
    files_dict_wdf = {}

    files_analyzed = []
    while not entities_queue.empty():
        current_entity =  entities_queue.get()
        if current_entity in files_analyzed:
            #entity was analyzed once; no need to look again
            continue
        # print 'processing ',current_entity
        files_analyzed.append(current_entity)

        if filter_entity(current_entity):
            continue

        # obtain activity who used this entity
        current_activities = []
        for key in used:
            if used[key]['prov:entity'] == current_entity:
                current_activities.append(used[key]['prov:activity'])
        if len(current_activities)>1:
            print "STRANGE: file ",current_entity, ' was used by more activities:',str(current_activities)

        if len(current_activities)>0:
            for current_activity_index in current_activities:
                #obtain list of entities which were generated by current_activity
                for key in wasgeneratedby:
                    if wasgeneratedby[key]['prov:activity'] == current_activity_index:
                        # wasgeneratedby all entities used by current activity
                        wgb_entity = wasgeneratedby[key]['prov:entity']

                        if not filter_entity(wgb_entity):
                            wdf_count+=1

                            files_dict_wdf[namespace+':wDF'+str(wdf_count)]={'prov:usedEntity':current_entity,
                             'prov:generatedEntity':wgb_entity}
                            files_selected.append(wgb_entity)
                            entities_queue.put(wgb_entity)
                            # print "adding ", wgb_entity
                        # else :
                        #     print " not counting:"
                        #     print "usedEntity     : ", current_entity
                        #     print "generatedEntity: ",wgb_entity
        else:
            # print "no activity for ",current_entity
            pass

    print
    rez={'entity':{},'wasDerivedFrom':files_dict_wdf,'prefix':json_dict['prefix']}
    for file in files_selected:
        rez['entity'][file]= json_dict['entity'][file]
    # print json.dumps(rez, indent=4, sort_keys=True)
    return rez

def create_activities_json(json_dict):

    rez={'activity':json_dict['activity'],
         'wasInformedBy':json_dict['wasInformedBy'],
         'prefix':json_dict['prefix']
         }

    # print json.dumps(rez, indent=4, sort_keys=True)
    return rez

if __name__ == "__main__":

    with open(file_in) as json_file:
        json_dict = json.load(json_file)
        #print(json_dict)

    rez = create_entities_json(json_dict)
    with open(file_out_entities, 'w') as outfile:
        json.dump(rez, outfile, sort_keys = True, indent = 4)

    rez = create_activities_json(json_dict)
    with open(file_out_activities, 'w') as outfile:
        json.dump(rez, outfile, sort_keys = True, indent = 4)
